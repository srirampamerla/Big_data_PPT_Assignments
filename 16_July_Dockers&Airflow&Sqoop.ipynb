{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba97efcf-1f56-4999-b244-d168b414de91",
   "metadata": {},
   "source": [
    "TOPIC: Docker\n",
    "1. Scenario: You are building a microservices-based application using Docker. Design a Docker Compose file that sets up three containers: a web server container, a database container, and a cache container. Ensure that the containers can communicate with each other properly.\n",
    "2. Scenario: You want to scale your Docker containers dynamically based on the incoming traffic. Write a Python script that utilizes Docker SDK to monitor the CPU usage of a container and automatically scales the number of replicas based on a threshold.\n",
    "3. Scenario: You have a Docker image stored on a private registry. Develop a script in Bash that authenticates with the registry, pulls the latest version of the image, and runs a container based on that image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64310f5-dcf9-4113-85bf-d2cf979c3583",
   "metadata": {},
   "outputs": [],
   "source": [
    "version: '3'\n",
    "services:\n",
    "  webserver:\n",
    "    image: nginx:latest\n",
    "    ports:\n",
    "      - 80:80\n",
    "    depends_on:\n",
    "      - database\n",
    "      - cache\n",
    "\n",
    "  database:\n",
    "    image: mysql:latest\n",
    "    environment:\n",
    "      - MYSQL_ROOT_PASSWORD=your_root_password\n",
    "      - MYSQL_DATABASE=your_database\n",
    "      - MYSQL_USER=your_user\n",
    "      - MYSQL_PASSWORD=your_password\n",
    "\n",
    "  cache:\n",
    "    image: redis:latest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f872d8-4f4f-4368-b26c-84ecd2847b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker-compose up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b556a71-8450-4e92-9fc0-fc3ee1efb84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docker\n",
    "import psutil\n",
    "\n",
    "# Docker SDK client\n",
    "client = docker.from_env()\n",
    "\n",
    "# Container details\n",
    "container_name = \"your_container_name\"\n",
    "threshold = 70  # CPU usage threshold in percentage\n",
    "\n",
    "# Get the container object\n",
    "container = client.containers.get(container_name)\n",
    "\n",
    "while True:\n",
    "    # Get the current CPU usage of the container\n",
    "    cpu_percent = psutil.cpu_percent(interval=1)\n",
    "\n",
    "    # Scale the number of replicas based on the threshold\n",
    "    if cpu_percent > threshold:\n",
    "        container.scale(2)  # Scale up to 2 replicas\n",
    "        print(\"Scaling up...\")\n",
    "    else:\n",
    "        container.scale(1)  # Scale down to 1 replica\n",
    "        print(\"Scaling down...\")\n",
    "\n",
    "    # Sleep for a specific interval before checking again\n",
    "    time.sleep(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9af8b30-8a68-4ace-8d99-5d5116ee0bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "# Registry authentication details\n",
    "registry_url=\"your_registry_url\"\n",
    "registry_username=\"your_username\"\n",
    "registry_password=\"your_password\"\n",
    "\n",
    "# Docker image details\n",
    "image_name=\"your_image_name\"\n",
    "container_name=\"your_container_name\"\n",
    "\n",
    "# Authenticate with the private registry\n",
    "docker login \"$registry_url\" --username \"$registry_username\" --password \"$registry_password\"\n",
    "\n",
    "# Pull the latest version of the image from the registry\n",
    "docker pull \"$registry_url/$image_name\"\n",
    "\n",
    "# Run a container based on the image\n",
    "docker run --name \"$container_name\" -d \"$registry_url/$image_name\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74663eb-75d6-4485-8aab-25d7e6b42ed8",
   "metadata": {},
   "source": [
    "TOPIC: Airflow\n",
    "1. Scenario: You have a data pipeline that requires executing a shell command as part of a task. Create an Airflow DAG that includes a BashOperator to execute a specific shell command.\n",
    "2. Scenario: You want to create dynamic tasks in Airflow based on a list of inputs. Design an Airflow DAG that generates tasks dynamically using PythonOperator, where each task processes an element from the input list.\n",
    "3. Scenario: You need to set up a complex task dependency in Airflow, where Task B should start only if Task A has successfully completed. Implement this dependency using the \"TriggerDagRunOperator\" in Airflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1779d920-db26-4e4d-bcf5-1b05679ce2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow import DAG\n",
    "from airflow.operators.bash_operator import BashOperator\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the DAG\n",
    "dag = DAG(\n",
    "    dag_id='execute_shell_command',\n",
    "    start_date=datetime(2022, 1, 1),\n",
    "    schedule_interval=None\n",
    ")\n",
    "\n",
    "# Define the BashOperator task\n",
    "execute_command_task = BashOperator(\n",
    "    task_id='execute_command',\n",
    "    bash_command='your_shell_command',\n",
    "    dag=dag\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82fa5d0-e8ab-42d6-89ec-e5a46128a408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow import DAG\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "from datetime import datetime\n",
    "\n",
    "# List of inputs\n",
    "input_list = ['input1', 'input2', 'input3']\n",
    "\n",
    "# Function to process an input\n",
    "def process_input(input):\n",
    "    # Process the input\n",
    "    print(f\"Processing input: {input}\")\n",
    "\n",
    "# Define the DAG\n",
    "dag = DAG(\n",
    "    dag_id='dynamic_tasks',\n",
    "    start_date=datetime(2022, 1, 1),\n",
    "    schedule_interval=None\n",
    ")\n",
    "\n",
    "# Generate tasks dynamically\n",
    "for input in input_list:\n",
    "    task_id = f\"process_input_{input}\"\n",
    "    task = PythonOperator(\n",
    "        task_id=task_id,\n",
    "        python_callable=process_input,\n",
    "        op_args=[input],\n",
    "        dag=dag\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f10a4c1-531d-4ba3-9a8b-07377f554b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow import DAG\n",
    "from airflow.operators.dagrun_operator import TriggerDagRunOperator\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the DAG\n",
    "dag = DAG(\n",
    "    dag_id='task_dependency',\n",
    "    start_date=datetime(2022, 1, 1),\n",
    "    schedule_interval=None\n",
    ")\n",
    "\n",
    "# Define Task A\n",
    "task_a = ...\n",
    "\n",
    "# Define Task B\n",
    "task_b = ...\n",
    "\n",
    "# Define the TriggerDagRunOperator\n",
    "trigger_task_b = TriggerDagRunOperator(\n",
    "    task_id='trigger_task_b',\n",
    "    trigger_dag_id='task_dependency',\n",
    "    execution_date=\"{{ execution_date }}\",\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "# Set the task dependencies\n",
    "task_a >> trigger_task_b >> task_b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd69044d-053a-4715-8f8b-6ac603595e46",
   "metadata": {},
   "source": [
    "TOPIC: Sqoop\n",
    "1. Scenario: You want to import data from an Oracle database into Hadoop using Sqoop, but you only need to import specific columns from a specific table. Write a Sqoop command that performs the import, including the necessary arguments for column selection and table mapping.\n",
    "2. Scenario: You have a requirement to perform an incremental import of data from a MySQL database into Hadoop using Sqoop. Design a Sqoop command that imports only the new or updated records since the last import.\n",
    "3. Scenario: You need to export data from Hadoop to a Microsoft SQL Server database using Sqoop. Develop a Sqoop command that exports the data, considering factors like database connection details, table mapping, and appropriate data types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a1c2a3-fc6d-4b05-b995-6af3bea70aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqoop import \\\n",
    "  --connect jdbc:oracle:thin:@<oracle_host>:<oracle_port>:<oracle_sid> \\\n",
    "  --username <username> \\\n",
    "  --password <password> \\\n",
    "  --table <table_name> \\\n",
    "  --columns \"<column1>,<column2>,<column3>\" \\\n",
    "  --target-dir <target_directory>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521ab031-18f1-4bec-891b-260298d1ba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqoop import \\\n",
    "  --connect jdbc:mysql://<mysql_host>:<mysql_port>/<database_name> \\\n",
    "  --username <username> \\\n",
    "  --password <password> \\\n",
    "  --table <table_name> \\\n",
    "  --incremental append \\\n",
    "  --check-column <column_name> \\\n",
    "  --last-value <last_imported_value> \\\n",
    "  --target-dir <target_directory>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b3e3ca-f2c2-4fe4-a8a8-7f3ed52c7e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqoop export \\\n",
    "  --connect \"jdbc:sqlserver://<sqlserver_host>:<sqlserver_port>;database=<database_name>\" \\\n",
    "  --username <username> \\\n",
    "  --password <password> \\\n",
    "  --table <table_name> \\\n",
    "  --export-dir <hadoop_directory> \\\n",
    "  --input-fields-terminated-by ',' \\\n",
    "  --input-lines-terminated-by '\\n' \\\n",
    "  --input-null-string '\\\\N' \\\n",
    "  --input-null-non-string '\\\\N'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab65305-8b47-4aa3-a03c-a6ad31d9b5f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
