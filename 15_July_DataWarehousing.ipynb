{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07f6f87d-eab8-4fc7-9950-ab135018f8ba",
   "metadata": {},
   "source": [
    "TOPIC: Data Warehousing Fundamentals\n",
    "   1. Design a data warehouse schema for a retail company that includes dimension tables for products, customers, and time. Implement the schema using a relational database management system (RDBMS) of your choice.\n",
    "   2. Create a fact table that captures sales data, including product ID, customer ID, date, and sales amount. Populate the fact table with sample data.\n",
    "   3. Write SQL queries to retrieve sales data from the data warehouse, including aggregations and filtering based on different dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d797450-5106-4917-93ba-f1179e2e9045",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Create Products dimension table\n",
    "CREATE TABLE Products (\n",
    "  product_id SERIAL PRIMARY KEY,\n",
    "  product_name VARCHAR(255) NOT NULL,\n",
    "  category VARCHAR(255) NOT NULL,\n",
    "  brand VARCHAR(255) NOT NULL\n",
    ");\n",
    "\n",
    "-- Create Customers dimension table\n",
    "CREATE TABLE Customers (\n",
    "  customer_id SERIAL PRIMARY KEY,\n",
    "  customer_name VARCHAR(255) NOT NULL,\n",
    "  address VARCHAR(255) NOT NULL,\n",
    "  email VARCHAR(255) NOT NULL\n",
    ");\n",
    "\n",
    "-- Create Time dimension table\n",
    "CREATE TABLE Time (\n",
    "  date_id SERIAL PRIMARY KEY,\n",
    "  date DATE NOT NULL,\n",
    "  year INT NOT NULL,\n",
    "  month INT NOT NULL,\n",
    "  day INT NOT NULL,\n",
    "  quarter INT NOT NULL,\n",
    "  fiscal_year INT NOT NULL\n",
    ");\n",
    "\n",
    "-- Create Sales fact table\n",
    "CREATE TABLE Sales (\n",
    "  sales_id SERIAL PRIMARY KEY,\n",
    "  product_id INT REFERENCES Products(product_id),\n",
    "  customer_id INT REFERENCES Customers(customer_id),\n",
    "  date_id INT REFERENCES Time(date_id),\n",
    "  sales_amount DECIMAL(10, 2) NOT NULL\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02269f7-1e2f-46f9-af2e-974b274606cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Insert sample data into the Sales fact table\n",
    "INSERT INTO Sales (product_id, customer_id, date_id, sales_amount)\n",
    "VALUES\n",
    "  (1, 1, 1, 100.00),\n",
    "  (2, 2, 1, 150.00),\n",
    "  (3, 3, 2, 200.00),\n",
    "  (1, 2, 3, 120.00),\n",
    "  (2, 1, 4, 180.00),\n",
    "  (3, 3, 4, 220.00);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05562d87-7783-4a98-808d-4c1ddd86828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT p.product_name,SUM(s.sales_amount) AS total_sales_amount FROM Products p\n",
    "JOIN Sales s ON p.product_id = s.product_id GROUP BY p.product_name;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada97a87-ef5f-4d0c-bb4d-018979a23ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT c.customer_name,SUM(s.sales_amount) AS total_sales_amount FROM Customers c\n",
    "JOIN Sales s ON c.customer_id = s.customer_id GROUP BY c.customer_name;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277a35d8-b0ee-4b64-9a59-f57ddb1daf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT t.year,t.month,SUM(s.sales_amount) AS total_sales_amount FROM Time t\n",
    "JOIN Sales s ON t.date_id = s.date_id WHERE t.year = 2022 GROUP BY t.year, t.month;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661ec528-6d5c-4f82-bc12-75fe2677924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTp.product_name,c.customer_name,t.date,s.sales_amount FROM Sales s\n",
    "JOIN Products p ON s.product_id = p.product_id \n",
    "JOIN Customers c ON s.customer_id = c.customer_id\n",
    "JOIN Time t ON s.date_id = t.date_id WHERE p.product_name = 'Product A' AND c.customer_name = 'John Doe' AND t.date = '2022-07-01';\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81175a10-82ae-472d-a106-0533106c00e4",
   "metadata": {},
   "source": [
    "TOPIC: ETL and Data Integration\n",
    "  1. Design an ETL process using a programming language (e.g., Python) to extract data from a source system (e.g., CSV files), transform it by applying certain business rules or calculations, and load it into a data warehouse.\n",
    "  2. Implement the ETL process by writing code that performs the extraction, transformation, and loading steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564af055-d53c-4199-b1f4-6c28b830b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Extraction\n",
    "source_files = ['file1.csv', 'file2.csv']\n",
    "dataframes = []\n",
    "for file in source_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Transformation\n",
    "transformed_data = pd.concat(dataframes)\n",
    "transformed_data['total_sales'] = transformed_data['quantity'] * transformed_data['unit_price']\n",
    "\n",
    "# Loading\n",
    "data_warehouse_connection = your_data_warehouse_connection\n",
    "transformed_data.to_sql('sales_data', data_warehouse_connection, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbe0821-3a8c-4235-8a43-08849186718d",
   "metadata": {},
   "source": [
    "TOPIC: Dimensional Modeling and Schemas\n",
    "   1. Design a star schema for a university database, including a fact table for student enrollments and dimension tables for students, courses, and time. Implement the schema using a database of your choice.\n",
    "   2. Write SQL queries to retrieve data from the star schema, including aggregations and joins between the fact table and dimension tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d50c384-6566-44c7-b358-0907c98587dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Create Students dimension table\n",
    "CREATE TABLE Students (\n",
    "  student_id SERIAL PRIMARY KEY,\n",
    "  student_name VARCHAR(255) NOT NULL,\n",
    "  student_major VARCHAR(255) NOT NULL,\n",
    "  student_level VARCHAR(255) NOT NULL\n",
    ");\n",
    "\n",
    "-- Create Courses dimension table\n",
    "CREATE TABLE Courses (\n",
    "  course_id SERIAL PRIMARY KEY,\n",
    "  course_name VARCHAR(255) NOT NULL,\n",
    "  course_department VARCHAR(255) NOT NULL,\n",
    "  course_credits INT NOT NULL\n",
    ");\n",
    "\n",
    "-- Create Time dimension table\n",
    "CREATE TABLE Time (\n",
    "  date_id SERIAL PRIMARY KEY,\n",
    "  date DATE NOT NULL,\n",
    "  year INT NOT NULL,\n",
    "  month INT NOT NULL,\n",
    "  day INT NOT NULL,\n",
    "  semester VARCHAR(255) NOT NULL\n",
    ");\n",
    "\n",
    "-- Create Enrollments fact table\n",
    "CREATE TABLE Enrollments (\n",
    "  enrollment_id SERIAL PRIMARY KEY,\n",
    "  student_id INT REFERENCES Students(student_id),\n",
    "  course_id INT REFERENCES Courses(course_id),\n",
    "  date_id INT REFERENCES Time(date_id),\n",
    "  grade VARCHAR(2) NOT NULL\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba41805f-f567-4a90-a07c-6a2ca4f76c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT c.course_name,COUNT(e.enrollment_id) AS total_enrollments FROM Courses c\n",
    "JOIN Enrollments e ON c.course_id = e.course_id GROUP BY c.course_name;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e0f70c-e223-4c59-a434-9f19cec18e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT s.student_name, AVG(CAST(e.grade AS INTEGER)) AS average_grade FROM Students s\n",
    "JOIN Enrollments e ON s.student_id = e.student_id GROUP BY s.student_name;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e906e895-a69c-45d5-8fd3-899e700c9b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT t.semester,COUNT(e.enrollment_id) AS total_enrollments FROM Time t\n",
    "JOIN Enrollments e ON t.date_id = e.date_id GROUP BY t.semester;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0df20c-babe-44e9-87a1-7545b234270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT s.student_name,c.course_name,e.grade FROM Enrollments e\n",
    "JOIN Students s ON e.student_id = s.student_id\n",
    "JOIN Courses c ON e.course_id = c.course_id WHERE e.enrollment_id = 1;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3175b9fe-cecf-42ff-b484-970bcdbf65e0",
   "metadata": {},
   "source": [
    "TOPIC: Performance Optimization and Querying\n",
    "    1. Scenario: You need to improve the performance of your data loading process in the data warehouse. Write a Python script that implements the following optimizations:\n",
    "Utilize batch processing techniques to load data in bulk instead of individual row insertion.\n",
    "      b)  Implement multi-threading or multiprocessing to parallelize the data loading process.\n",
    "      c)  Measure the time taken to load a specific amount of data before and after implementing these optimizations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4215bc-2540-471e-a1bb-838a2efda12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "from multiprocessing import Pool\n",
    "import psycopg2\n",
    "\n",
    "# Function to load data into the data warehouse\n",
    "def load_data(data):\n",
    "    # Connect to the data warehouse\n",
    "    conn = psycopg2.connect(host=\"localhost\", port=\"5432\", database=\"your_database\", user=\"your_username\", password=\"your_password\")\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Prepare the data for insertion (example: assume data is a list of tuples)\n",
    "    values = ','.join(cursor.mogrify('(%s,%s,%s)', row).decode() for row in data)\n",
    "\n",
    "    # Bulk insert the data\n",
    "    insert_query = f\"INSERT INTO your_table (col1, col2, col3) VALUES {values};\"\n",
    "    cursor.execute(insert_query)\n",
    "    conn.commit()\n",
    "\n",
    "    # Close the database connection\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "# Function to measure the time taken for data loading\n",
    "def measure_time_taken(data):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Approach 2: Multiprocessing\n",
    "    pool = Pool()\n",
    "    pool.map(load_data, data, chunksize=batch_size)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    time_taken = end_time - start_time\n",
    "    print(f\"Time taken: {time_taken} seconds\")\n",
    "\n",
    "# Define your data and batch size\n",
    "data = [(1, 'John', 25), (2, 'Jane', 30), (3, 'David', 28)]  # Example data\n",
    "batch_size = 1000  # Adjust the batch size according to your data size and performance requirements\n",
    "\n",
    "# Measure the time taken to load data before optimization\n",
    "measure_time_taken(data)\n",
    "\n",
    "# Measure the time taken to load data after optimization\n",
    "measure_time_taken(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
